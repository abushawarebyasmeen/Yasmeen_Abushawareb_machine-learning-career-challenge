# -*- coding: utf-8 -*-
"""data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15KrEFwn2mUwI2Msy_Q36PgVPDQ2GEStr
"""

from numpy import genfromtxt
from PIL import Image
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms
import torch

# Eğitim verisini eğitim ve doğrulama olarak ikiye ayırır
def train_val_split(train_dataset):
    train_size = int(len(train_dataset) * 0.8)
    val_size = len(train_dataset) - train_size
    train_subset, val_subset = random_split(train_dataset, [train_size, val_size],
                                            generator=torch.Generator().manual_seed(42))
    return train_subset, val_subset

# Test verisi için görüntü dönüşümleri
transform_test = transforms.Compose([
  transforms.CenterCrop(224),
  transforms.ToTensor(),
  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]
)

# Görüntü veri seti sınıfı
class FoodDataset(Dataset):
    def __init__(self, data_csv, transforms=None):
        self.data = genfromtxt(data_csv, delimiter=',', dtype=str)
        self.transforms = transforms

    def __getitem__(self, index):
        fp, _, idx = self.data[index]
        idx = int(idx)
        img = Image.open(fp)
        if self.transforms is not None:
            img = self.transforms(img)
        return (img, idx)

    def __len__(self):
        return len(self.data)

# Belirli CSV dosyasından veri seti oluşturur
def get_dataset(csv_path, transform):
    return FoodDataset(csv_path, transform)

# Eğitim, doğrulama ve test verileri için DataLoader oluşturur
def create_dataloaders(train_set, val_set, test_set, args=None):
    train_loader = DataLoader(train_set, batch_size=30, shuffle=True)
    validation_loader = DataLoader(val_set, batch_size=30, shuffle=False)
    test_loader = DataLoader(test_set, batch_size=30, shuffle=False)

    return train_loader, validation_loader, test_loader

# CSV dosyalarından veriyi alır, dönüştürür ve DataLoader'lara çevirir
def get_dataloaders(train_csv, test_csv, args=None):

    # Eğitim verisi için dönüşümler (ortalama ve std dev. normalize)
    transform_train = transforms.Compose([
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5689, 0.4313, 0.2897], std=[0.2537, 0.2548, 0.2444])]
    )

    # Veri setlerini oluştur
    train_dataset = get_dataset(train_csv, transform_train)
    test_dataset = get_dataset(test_csv, transform_test)

    # Eğitim ve doğrulama verisini ayır
    train_set, val_set = train_val_split(train_dataset)

    # Dataloader'ları oluştur ve döndür
    train_loader, validation_loader, test_loader = create_dataloaders(train_set, val_set, test_dataset, args=None)

    return train_loader, validation_loader, test_loader